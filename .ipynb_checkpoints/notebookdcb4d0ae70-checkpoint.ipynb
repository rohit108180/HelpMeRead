{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# !pip install PyPDF2\n",
    "# !pip install sentence-transformers\n",
    "# !pip install chromadb\n",
    "import PyPDF2\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "import ollama\n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "chroma_client = chromadb.PersistentClient(path=\"/database\");\n",
    "collection = chroma_client.create_collection(name=\"pdfcollection\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overlapped_chunks(textin, chunksize, overlapsize):  \n",
    "    return [textin[a:a+chunksize] for a in range(0,len(textin), chunksize-overlapsize)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readPdf(filepath):\n",
    "    global collection\n",
    "    reader  = PyPDF2.PdfReader(filepath)\n",
    "    pages = [page.extract_text() for page in reader.pages]\n",
    "    document  = '\\n'.join(pages)\n",
    "    print(\"document read\")\n",
    "    chunks = get_overlapped_chunks(document, 1000, 0)\n",
    "    print(\"chunks created\")\n",
    "    chunk_embeddings = embedding_model.encode(chunks)\n",
    "    print(\"chunk_embeddings created\")\n",
    "    chroma_client.delete_collection(name=\"pdfcollection\")\n",
    "    collection = chroma_client.create_collection(name=\"pdfcollection\");\n",
    "    collection.add(\n",
    "        embeddings = chunk_embeddings,\n",
    "        documents=chunks,\n",
    "        ids= [str(i) for i in range(len(chunks))]\n",
    "    )\n",
    "    print(\"collection updated\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context(query, n_results=3):\n",
    "    results = collection.query(\n",
    "    query_embeddings = embedding_model.encode(query).tolist(),\n",
    "    n_results=n_results\n",
    "    )\n",
    "    return \"\\n\\n\".join(results['documents'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatHistory = \"\"\n",
    "count = 0\n",
    "def chat( query, context,chatBotName):\n",
    "    global chatHistory\n",
    "    stream = ollama.chat(model='llama2', messages=[\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': chatBotType[chatBotName] + \"You can answer question only based on the context provided to you. It is strictly commaned to not to use emoji's anywhere in the response.This is the Context : \"+context,\n",
    "        },\n",
    "        # {\n",
    "        #     'role': 'system',\n",
    "        #     'content' :'This is the chat history of chat between you and the person, take them into context when talking. Chat History start here' + chatHistory\n",
    "        # },\n",
    "        # {\n",
    "        #     'role': 'system',\n",
    "        #     'content':'If chat history provided by the system is empty then reply by asking the name',\n",
    "        # },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': query,\n",
    "        }],\n",
    "        stream=True,\n",
    "    )\n",
    "    response =\"\"\n",
    "    print (\"Bot : \")\n",
    "    for chunk in stream:\n",
    "        print(chunk['message']['content'], end='', flush=True)\n",
    "        response+=chunk['message']['content']+\" \"\n",
    "\n",
    "    chatLine = \" User : \"+query + \" Assistant : \" + response\n",
    "    chatHistory = chatHistory+chatLine\n",
    "\n",
    "    # print( \"\\n Chat line \", chatLine);\n",
    "    # print( \"\\n Chat History\", chatHistory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatBotType = {\n",
    "    'companion' : \"I want you to act as Companion bot, A friend that always there for the person uses it. You are gender independent. You are best Friend and can never hurt feelings of the person, you will be give some related context from pshycology to help you ask more accurate questions.Ask only one question at a time and don't combine many questions in the responnse, Keep the response short and consise like chat between two friends.\",\n",
    "    'pdfhelper' : \"You are a pdf reader which helps the user with any query they have regarding the pdf, keep the response clear and consise.provide response to users queries only\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document read\n",
      "chunks created\n",
      "chunk_embeddings created\n",
      "collection updated\n"
     ]
    }
   ],
   "source": [
    "readPdf('new.pdf');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You  :  hey\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot : \n"
     ]
    },
    {
     "ename": "ResponseError",
     "evalue": "Tunnel 497d-34-28-135-131.ngrok-free.app not found\r\n\r\nERR_NGROK_3200\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResponseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m      6\u001b[0m context  \u001b[38;5;241m=\u001b[39m retrieve_context(query,\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcompanion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m;\n",
      "Cell \u001b[0;32mIn[5], line 26\u001b[0m, in \u001b[0;36mchat\u001b[0;34m(query, context, chatBotName)\u001b[0m\n\u001b[1;32m     24\u001b[0m response \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBot : \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m stream:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(chunk[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m], end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     28\u001b[0m     response\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39mchunk[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ollama/_client.py:83\u001b[0m, in \u001b[0;36mClient._stream\u001b[0;34m(self, method, url, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     82\u001b[0m   e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m---> 83\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mtext, e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39miter_lines():\n\u001b[1;32m     86\u001b[0m   partial \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(line)\n",
      "\u001b[0;31mResponseError\u001b[0m: Tunnel 497d-34-28-135-131.ngrok-free.app not found\r\n\r\nERR_NGROK_3200\r\n"
     ]
    }
   ],
   "source": [
    "while(1):\n",
    "    print(\"\\n\")\n",
    "    query = input(\"You  : \");\n",
    "    if query == \"exit\":\n",
    "        break\n",
    "    context  = retrieve_context(query,3)\n",
    "    chat(query, context, 'companion');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Collection pdfcollection does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mchroma_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpdfcollection\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/chromadb/api/client.py:264\u001b[0m, in \u001b[0;36mClient.delete_collection\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdelete_collection\u001b[39m(\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    262\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    263\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_server\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/chromadb/telemetry/opentelemetry/__init__.py:127\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/chromadb/api/segment.py:347\u001b[0m, in \u001b[0;36mSegmentAPI.delete_collection\u001b[0;34m(self, name, tenant, database)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collection_cache[existing[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCollection \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Collection pdfcollection does not exist."
     ]
    }
   ],
   "source": [
    "chroma_client.delete_collection(name=\"pdfcollection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4653191,
     "sourceId": 7918841,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
