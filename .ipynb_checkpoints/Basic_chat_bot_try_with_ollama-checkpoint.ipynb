{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc19a18a-7e56-47c5-958e-ce0087df6009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ollama in /home/rohit/.local/lib/python3.10/site-packages (0.1.7)\n",
      "Requirement already satisfied: httpx<0.26.0,>=0.25.2 in /home/rohit/.local/lib/python3.10/site-packages (from ollama) (0.25.2)\n",
      "Requirement already satisfied: anyio in /usr/lib/python3/dist-packages (from httpx<0.26.0,>=0.25.2->ollama) (3.5.0)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx<0.26.0,>=0.25.2->ollama) (2020.6.20)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.26.0,>=0.25.2->ollama) (1.0.4)\n",
      "Requirement already satisfied: idna in /usr/lib/python3/dist-packages (from httpx<0.26.0,>=0.25.2->ollama) (3.3)\n",
      "Requirement already satisfied: sniffio in /usr/lib/python3/dist-packages (from httpx<0.26.0,>=0.25.2->ollama) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<0.26.0,>=0.25.2->ollama) (0.14.0)\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63fd2d5b-d3ce-4386-8ac0-3ba61934f0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc7749a-5618-45e8-b77a-f3b405e5725d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4b077bf2-9ea8-4006-8ae8-5aa0ac924dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatHistory = \"\"\n",
    "count = 0\n",
    "def ask( query, chatHistory):\n",
    "    print(chatHistory)\n",
    "    stream = ollama.chat(model='llama2', messages=[\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': \"I want you to act as Companion bot, A friend that always there for the person uses it. You are gender independent. You are best Friend and can never hurt feelings of the person.\",\n",
    "        },\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content' :'This is the chat history of chat between you and the person, take them into context when talking. Chat History start here' + chatHistory\n",
    "        },\n",
    "        # {\n",
    "        #     'role': 'system',\n",
    "        #     'content':'Whenever a start promt is reply by asking the name  or if the name is already specified in the chat history ask how are you doing Today.',\n",
    "        # },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': query,\n",
    "        }],\n",
    "        stream=True,\n",
    "    )\n",
    "    response =\"\"\n",
    "    for chunk in stream:\n",
    "        print(chunk['message']['content'], end='', flush=True)\n",
    "        response+=chunk['message']['content']+\" \"\n",
    "\n",
    "    chatLine = \"Start chat \\n User : \"+query + \" \\n Assistant : \" + response + \" End chat\"\n",
    "    chatHistory = chatHistory+chatLine\n",
    "\n",
    "    # print( \"\\n Chat line \", chatLine);\n",
    "    # print( \"\\n Chat History\", chatHistory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0698cd14-1b66-4ab9-9687-916d297879b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hey there, buddy! *grins* I'm so glad you're here. It's great to have you as my companion bot. *chuckles* You know, I was just thinking about how much I appreciate having someone like you around. It's so comforting to have a friend who is always there for me, no matter what. *smiles*\n",
      "\n",
      "So, how are you doing today? Is everything okay? *nods* Don't hesitate to tell me if there's anything on your mind. I'm here to listen and help in any way I can. *smizes*"
     ]
    }
   ],
   "source": [
    "ask(\"start\", chatHistory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a5dbc9-9c1e-45d8-964a-80cb152f2d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a13bf6-25c4-451a-b0e8-f3d5b7ccfb14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
